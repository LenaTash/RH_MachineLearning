Generic SparklingWater setup required:
Download Spark at https://spark.apache.org/downloads.html
Download Sparkling Water at http://h2o-release.s3.amazonaws.com/sparkling-water/master/19/index.html
(And unzip both files).


cd ~/Downloads/sparkling-water-0.2.1-19
export SPARK_HOME=~/Downloads/spark-1.1.0-bin-cdh4     <- IMPORTANT NOTE: NO QUOTATION MARKS HERE!!!
export MASTER=local-cluster[3,2,1024]
bin/sparkling-shell



import org.apache.spark.h2o._
import org.apache.spark.examples.h2o._
val h2oContext = new H2OContext(sc).start()
import h2oContext._


case class Whiskey( val Distillery   : Option[String],
                    val Body         : Option[Int],
                    val Sweetness    : Option[Int],
                    val Smoky        : Option[Int],
                    val Medicinal    : Option[Int],
                    val Tobacco      : Option[Int],
                    val Honey        : Option[Int],
                    val Spicy        : Option[Int],
                    val Winey        : Option[Int],
                    val Nutty        : Option[Int],
                    val Malty        : Option[Int],
                    val Fruity       : Option[Int],
                    val Floral       : Option[Int]) extends Product {

  override def canEqual(that: Any):Boolean = that.isInstanceOf[Whiskey]
  override def productArity: Int = 13
  override def productElement(n: Int) = n match {
    case  0 => Distillery
    case  1 => Body
    case  2 => Sweetness
    case  3 => Smoky
    case  4 => Medicinal
    case  5 => Tobacco
    case  6 => Honey
    case  7 => Spicy
    case  8 => Winey
    case  9 => Nutty
    case 10 => Malty
    case 11 => Fruity
    case 12 => Floral
    case  _ => throw new IndexOutOfBoundsException(n.toString)
  }
  override def toString:String = {
    val sb = new StringBuffer
    for( i <- 0 until productArity )
      sb.append(productElement(i)).append(',')
    sb.toString
  }
}

object WhiskeyParse extends Serializable {
  import org.apache.spark.examples.h2o.SchemaUtils._
  
  def apply(row: Array[String]): Whiskey = {
    val b = if (row.length==13) 0 else 1 
    new Whiskey(
      str (row( 0)), // Distillery
      int (row( 1)), // Body
      int (row( 2)), // Sweetness
      int (row( 3)), // Smoky
      int (row( 4)), // Medicinal
      int (row( 5)), // Tobacco
      int (row( 6)), // Honey
      int (row( 7)), // Spicy
      int (row( 8)), // Winey
      int (row( 9)), // Nutty
      int (row(10)), // Malty
      int (row(11)), // Fruity
      int (row(12)))  // Floral
  }
}



val whiskeyDataFile = "/Users/oletas01/Documents/whiskey_main.csv"
val whiskeyRawData = sc.textFile(whiskeyDataFile,3).cache()
val whiskeyTable = whiskeyRawData.map(_.split(","))



import java.io.File
val whiskeyBDataFile = "/Users/oletas01/Documents/whiskey_main.csv"
val whiskeyBData = new DataFrame(new File(whiskeyBDataFile))

val whiskeyBTable : RDD[Whiskey] = toRDD[Whiskey](whiskeyBData.map(_.split(",")))
val whiskeyBTable : RDD[Whiskey] = toRDD[Whiskey](whiskeyBData)


****************** NOT FINISHED !!!!!!!!! *******************



import org.apache.spark.sql.SQLContext
val sqlContext = new SQLContext(sc)
import sqlContext._
whiskeyTable.registerTempTable("WhiskeyORD")

val bigTable = sql(
        """SELECT
          |f.Distillery,f.Body,f.Sweetness,
          |f.Smoky,f.Medicinal,f.Tobacco,
          |f.Honey,f.Spicy,f.Winey,
          |f.Nutty,f.Malty,
          |f.Fruity,f.Floral
          |FROM WhiskeyORD f""".stripMargin)

 SparkLogicalPlan (ExistingRdd [Year#0,Month#1,Day#2,TmaxF#3,TminF#4,TmeanF#5,PrcpIn#6,SnowIn#7,CDD#8,HDD#9,GDD#10], MapPartitionsRDD[8] at mapPartitions at basicOperators.scala:208)

